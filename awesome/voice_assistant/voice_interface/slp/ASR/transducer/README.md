# Transducers
Real fast, real time.

## Sequence Transduction with Recurrent Neural Networks
- [arxiv](https://arxiv.org/pdf/1211.3711.pdf)
- 2012, ICML 2012 Workshop on Representation Learning, University of Toronto
- RNN Transducer, RNN-T (but we can use other model instead of RNN)

## Two-pass end-to-end speech recognition
- [Sainath, T. N., Pang, R., Rybach, D., He, Y., Prabhavalkar, R., Li, W., ... & Chiu, C. C. (2019). Two-pass end-to-end speech recognition. arXiv preprint arXiv:1908.10992.](https://arxiv.org/pdf/1908.10992.pdf)
- 2019, 
- the RNN-T model produces streaming predictions and the LAS decoder finalizes the prediction during inference

## Exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer
- [arxiv](https://arxiv.org/pdf/1801.00841.pdf)
- 2017, Google
- Key-features
  - encoder: initialized from a connectionist temporal classification-based (CTC) acoustic model
  - decoder: initialized from a recurrent neural network language model trained on text data alone
  - entire neural network: trained with the RNN-T loss
  - sub-word units: capture longer context and significantly reduce substitution errors
- Introduction
  - The ASR systems break down the problem into three main sub-problems: acoustic, pronunciation, language modeling
  - end-to-end models: single neural network can be used to directly recognize utterances
  - sequence-to-sequence models: entire input sequence is encoded before the output sequence may be decoded (bad for real-time streaming)
  - streaming encoder-decoder architectures: neural transducer, recurrent neural aligner (RNA), recurrent neural network transducer (RNN-T)
    - allow the output to be decoded as soon as the first input is encoded

## Transformer transducer: A streamable speech recognition model with transformer encoders and rnn-t loss
- [arxiv](https://arxiv.org/pdf/2002.02562)
- Zhang, Qian, et al., ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020.
- 2020, Google Inc
- Similar to RNN-T but use Transformer encoder instead of RNN 
- Modules
  - Audio Encoder
  - Label Encoder
  - Joint Network

## Developing RNN-T Models Surpassing High-Performance Hybrid Models with Customization Capability
- [arxiv](https://arxiv.org/pdf/2007.15188.pdf)
- 2020, Microsoft Speech and Language Group
- Improving RNN-T Models
  - Saving GPU memory
    - A practical challenge: cannot fit too many speech frames in a minibatch (large data)
    - several 3-dimension tensors consume large amount of GPU memories
    - improve tokenization of word-piece units (WPUs)
  - Improving initialization
  - Improving encoder
  - Customizing RNN-T models with text-only data

## Developing Real-Time Streaming Transformer Transducer For Speech Recognition on Large-Scale Dataset
- [arxiv](https://arxiv.org/pdf/2010.11395.pdf)
- 2021, Microsoft.
- Real Time (RTF < 1)
- transducer architecture
- Transformer-XL and chunk-wise streaming

## Context-Aware Transformer Transducer for Speech Recognition
- [arxiv](https://arxiv.org/abs/2111.03250)
- 2021, Amazon Alexa
- leverage pretrained BERT based models to encode contextual data 
- Modules
  - Audio Encoder
  - Label Encoder
  - Context Encoder
  - Joint Network
- Dataset
  - Amazon in-house de-identified far-field dataset: train, valid, test = 910 , 195, 195 (hours)

## An All-Neural On-Device Speech Recognizer
- [Blog](https://ai.googleblog.com/2019/03/an-all-neural-on-device-speech.html)
- RNN-T
- real-time
- parallel implementation
- decoder ~= a Finite State Transducer (FST)
- all-neural, on-device Gboard speech recognizer on all Pixel phones (American English only)

## Sequence-to-sequence learning with Transducers
- [Blog](https://lorenlugosch.github.io/posts/2020/11/transducer/)
- Encoder, Predictor and Joiner
- one may recognize that the Transducer graph is a weighted FST
  - an alignment forms the input labels
  - y forms the output labels
  - and the weight for each edge is dynamically generated by the joiner network

